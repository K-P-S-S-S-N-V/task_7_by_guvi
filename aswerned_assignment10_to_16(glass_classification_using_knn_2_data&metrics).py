# -*- coding: utf-8 -*-
"""Aswerned_Assignment10 to 16(Glass_classification_using_KNN-2_Data&Metrics).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KICwzL_3zcOR9Q8ZzmFeSD-iymP4tzSx

Note: 1st Import Modules Pandas, Matplotlib, Numpy, Seaborn, Warnings - Filterwarnings, and Sklearn - Sklearn.model_selction - cross_val_score
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from warnings import filterwarnings
filterwarnings('ignore')
from sklearn.model_selection import cross_val_score

# Upload given dataset trainknn.csv file to Google colab
df_data=pd.read_csv("trainKNN.csv")

df_data.head()

df_data.describe()

df_data.info()

df_data.shape

df_data.dtypes # checking Data Types in given dataset

df_data.isnull().sum() #Checking Null data in given dataset

df_data[df_data.duplicated()]

df_data.drop_duplicates(keep="last",inplace=True)

df_data.shape

df_data[df_data.duplicated()]

df_data.head() # getting 5 lines data using .head()

df_data.columns  # Checking available Columns in dataset in advance

df_data["Type"].value_counts()

plt.figure(1, figsize=(5,5))
plt.title("Type percentage")
df_data['Type'].value_counts().plot.pie(autopct="%0.2f%%")

columns= [
    'RI',
    'Na',
    'Mg',
    'AI',
    'Si',
    'K',
    'Ca',
    'Ba',
    'Fe'
]

for i in df_data[columns].columns:
  sns.boxplot(df_data[columns][i])
  plt.xlabel(i)
  plt.show()

for i in df_data[columns].columns:
    sns.barplot(y=df_data[columns][i],x=df_data["Type"])
    plt.xlabel(i)
    plt.show()

for i in df_data[columns].columns:
    sns.violinplot(x=df_data["Type"],y=df_data[columns][i])
    plt.xlabel(i)
    plt.show()

plt.figure(figsize=(18,10))
sns.heatmap(df_data.corr(),annot=True,cmap='Dark2_r', linewidths = 2)

sns.pairplot(df_data)

#Outlier Treatment using IQR
df_data.head()  #recheck

df_data.shape #recheck

y_train = df_data['Type']
X_train = df_data.iloc[:,0:9]

X_train.head()

# print(f'Total # of sample in whole dataset: {len(X)}')
print(X_train.shape)
# print(X_test.shape)
print(y_train.shape)
# print(Y_test.shape)

X_train.head()

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()

X_train = ss.fit_transform(X_train)
#X_test = ss.transform(X_test)

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 4, metric = 'euclidean')
knn.fit(X_train, y_train)

KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,
                     weights='uniform')

print('[1]K Nearest Neighbor Training Accuracy:', knn.score(X_train, y_train)*100)

new_df=pd.read_csv("testKNN.csv") #upload and read testKNN.csv file

new_df.shape

y_test = new_df['Type']
X_test = new_df.iloc[:,0:9]

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
X_test = ss.fit_transform(X_test)

X_test.shape

y_pred = knn.predict(X_test)   # Predicting the Test set results

y_pred

y_test

from sklearn.metrics import accuracy_score
accu = accuracy_score(y_test, y_pred)

accu

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

k_range = range(1,25)
k_scores = []
error_rate =[]
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    #kscores - accuracy
    scores = cross_val_score(knn,X_train,df_data['Type'],cv=5,scoring='accuracy')
    k_scores.append(scores.mean())
    
    #error rate
    knn.fit(X_train,y_train)
    y_pred = knn.predict(X_test)
    error_rate.append(np.mean(y_pred!=y_test))

#plot k vs accuracy
plt.plot(k_range,k_scores)
plt.xlabel('value of k - knn algorithm')
plt.ylabel('Cross validated accuracy score')
plt.show()

#plot k vs error rate
plt.plot(k_range,error_rate)
plt.xlabel('value of k - knn algorithm')
plt.ylabel('Error rate')
plt.show()

from sklearn.neighbors import KNeighborsClassifier
knn1 = KNeighborsClassifier(n_neighbors = 4, metric = 'manhattan')
knn1.fit(X_train, y_train)

KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,
                     weights='uniform')

print('[1]K Nearest Neighbor Training Accuracy:', knn1.score(X_train, y_train)*100)

y_pred = knn1.predict(X_test)          # Predicting the Test set results

y_pred

from sklearn.metrics import accuracy_score
accu = accuracy_score(y_test, y_pred)

accu

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

